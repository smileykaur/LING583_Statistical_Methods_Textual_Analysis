{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Text Classification\n",
    "\n",
    "Improving text classifiction using LSI/NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from cytoolz import identity\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en', disable=['tagger', 'ner', 'parser'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_msgpack('http://bulba.sdsu.edu/rcv1_train.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    return [tok.orth_ for tok in nlp.tokenizer(text)]\n",
    "df['tokens'] = df['text'].apply(tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import *\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_extraction.text import *\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.decomposition import *\n",
    "from sklearn.preprocessing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8816664338814556, 0.0030277962191306404)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = make_pipeline(CountVectorizer(analyzer=identity), \n",
    "                   LogisticRegression())     \n",
    "lr_score = cross_val_score(lr, df['tokens'], df['politics'], cv=folds, n_jobs=-1)\n",
    "lr_score.mean(), lr_score.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimize hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('countvectorizer', CountVectorizer(analyzer=<cyfunction identity at 0x7f856b8e88e8>,\n",
       "        binary=False, decode_error='strict', dtype=<class 'numpy.int64'>,\n",
       "        encoding='utf-8', input='content', lowercase=True, max_df=1.0,\n",
       "        max_features=None, min_df=1, ngram_range=(1, 1), prepr...ty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'logisticregression__C': [0.01, 0.1, 1.0], 'countvectorizer__min_df': [1, 2], 'countvectorizer__max_df': [0.25, 0.5]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'logisticregression__C': [0.01, 0.1, 1.0],\n",
    "          'countvectorizer__min_df': [1, 2],\n",
    "          'countvectorizer__max_df': [0.25, 0.5]}\n",
    "grid_search = GridSearchCV(lr, params, n_jobs=-1, return_train_score=True)\n",
    "grid_search.fit(df['tokens'], df['politics'])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.89053303462959654, 0.0025217873309385753)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.set_params(**grid_search.best_params_)\n",
    "score = cross_val_score(lr, df['tokens'], df['politics'], cv=folds, n_jobs=-1)\n",
    "score.mean(), score.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LR + Latent Semantic Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lsa = make_pipeline(CountVectorizer(analyzer=identity), \n",
    "                    TfidfTransformer(norm='l2', use_idf=True),\n",
    "                    TruncatedSVD(300, n_iter=25), \n",
    "                    LogisticRegression())     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSI is computationally expensive, so this grid search can take a long time...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  36 out of  36 | elapsed: 11.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('countvectorizer', CountVectorizer(analyzer=<cyfunction identity at 0x7f856b8e88e8>,\n",
       "        binary=False, decode_error='strict', dtype=<class 'numpy.int64'>,\n",
       "        encoding='utf-8', input='content', lowercase=True, max_df=1.0,\n",
       "        max_features=None, min_df=1, ngram_range=(1, 1), prepr...ty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'logisticregression__C': [0.01, 0.1, 1.0], 'countvectorizer__min_df': [1, 2], 'countvectorizer__max_df': [0.25, 0.5]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'logisticregression__C': [0.01, 0.1, 1.0],\n",
    "          'countvectorizer__min_df': [1, 2],\n",
    "          'countvectorizer__max_df': [0.25, 0.5]}\n",
    "grid_search = GridSearchCV(lsa, params, n_jobs=-1, verbose=1, return_train_score=True)\n",
    "grid_search.fit(df['tokens'], df['politics'])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.88920056786672974, 0.0028572041447832508)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsa.set_params(**grid_search.best_params_)\n",
    "lsa_score = cross_val_score(lsa, df['tokens'], df['politics'], cv=folds, n_jobs=-1)\n",
    "lsa_score.mean(), lsa_score.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "Compare TruncatedSVD vs NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lsa = make_pipeline(CountVectorizer(analyzer=identity, min_df=2, max_df=0.25), \n",
    "                    TfidfTransformer(norm='l2', use_idf=True),\n",
    "                    TruncatedSVD(500, n_iter=25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('countvectorizer', CountVectorizer(analyzer=<cyfunction identity at 0x7f856b8e88e8>,\n",
       "        binary=False, decode_error='strict', dtype=<class 'numpy.int64'>,\n",
       "        encoding='utf-8', input='content', lowercase=True, max_df=0.25,\n",
       "        max_features=None, min_df=2, ngram_range=(1, 1), prep...uncatedSVD(algorithm='randomized', n_components=500, n_iter=25,\n",
       "       random_state=None, tol=0.0))])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsa.fit(df['tokens'], df['politics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "V = lsa.named_steps['countvectorizer'].get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percent U.S. $ 1 new million Clinton state Minister 2 \n",
      "0 1 2 6 3 4 7 5 : 8 \n",
      "Israel Israeli Palestinian Netanyahu peace Arafat Palestinians Jerusalem Hebron East \n",
      "Kong Hong China Chinese Taiwan Beijing Zaire rebels military refugees \n",
      "Kong Hong China percent Chinese Israel Beijing tax Taiwan Palestinian \n",
      "NATO Yeltsin Russia 0 Russian Moscow 1 alliance summit Clinton \n",
      "6 7 beat 4 NATO Yeltsin Russia 5 U.S. Russian \n",
      "Zaire percent refugees 6 tax Iraq Mobutu Kabila budget rebels \n",
      "party election Labour percent Zaire opposition elections Party parliament Mobutu \n",
      "Zaire Mobutu Kabila refugees Rwanda South Rwandan Africa Zairean Clinton \n"
     ]
    }
   ],
   "source": [
    "for d in range(10):\n",
    "    D = list(reversed(lsa.named_steps['truncatedsvd'].components_[d].argsort()))\n",
    "    for i in D[:10]:\n",
    "        print(V[i], end = ' ')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nmf = make_pipeline(CountVectorizer(analyzer=identity, min_df=2, max_df=0.25), \n",
    "                    TfidfTransformer(norm='l2', use_idf=True),\n",
    "                    NMF(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('countvectorizer', CountVectorizer(analyzer=<cyfunction identity at 0x7f856b8e88e8>,\n",
       "        binary=False, decode_error='strict', dtype=<class 'numpy.int64'>,\n",
       "        encoding='utf-8', input='content', lowercase=True, max_df=0.25,\n",
       "        max_features=None, min_df=2, ngram_range=(1, 1), prep...er=200,\n",
       "  n_components=50, random_state=None, shuffle=False, solver='cd',\n",
       "  tol=0.0001, verbose=0))])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmf.fit(df['tokens'], df['politics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labour Major Blair election Conservatives Britain Conservative party British Party \n",
      "0 1 2 3 4 5 b Results matches c \n",
      "Israel Palestinian Israeli Netanyahu Arafat peace Palestinians Jerusalem Hebron East \n",
      "China Chinese Beijing Deng Jiang rights human Xiaoping MFN trade \n",
      "Kong Hong China Tung British handover Chinese territory colony legislature \n",
      "NATO Russia alliance Moscow expansion enlargement Poland Europe summit Russian \n",
      "6 beat 7 4 3 2 5 tennis denotes Spain \n",
      "Cup season game second team points scored win goal match \n",
      "$ million company billion Inc money 1996 Corp pounds New \n",
      "refugees Zaire Rwanda Rwandan Hutu Zairean eastern U.N. UNHCR Tutsi \n"
     ]
    }
   ],
   "source": [
    "for d in range(10):\n",
    "    D = list(reversed(nmf.named_steps['nmf'].components_[d].argsort()))\n",
    "    for i in D[:10]:\n",
    "        print(V[i], end = ' ')\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
