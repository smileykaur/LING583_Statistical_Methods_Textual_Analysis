{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Text Classification\n",
    "\n",
    "Improving text classifiction using . . ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from cytoolz import identity\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en', disable=['ner', 'parser'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_msgpack('http://bulba.sdsu.edu/rcv1_train.dat')\n",
    "df = df.sample(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df['tokens'] = df['text'].apply(lambda d: [tok.orth_ for tok in nlp(d)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import *\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_extraction.text import *\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.decomposition import *\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.neighbors import *\n",
    "from sklearn.feature_selection import *\n",
    "from sklearn.ensemble import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.87799635159635159, 0.0069620288790832752)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = make_pipeline(CountVectorizer(analyzer=identity), \n",
    "                   LogisticRegression())     \n",
    "lr_score = cross_val_score(lr, df['tokens'], df['politics'], cv=folds, n_jobs=-1)\n",
    "lr_score.mean(), lr_score.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimize hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('countvectorizer', CountVectorizer(analyzer=<cyfunction identity at 0x7f4a8a4a0a58>,\n",
       "        binary=False, decode_error='strict', dtype=<class 'numpy.int64'>,\n",
       "        encoding='utf-8', input='content', lowercase=True, max_df=1.0,\n",
       "        max_features=None, min_df=1, ngram_range=(1, 1), prepr...ty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'logisticregression__C': [0.01, 0.1, 1.0], 'countvectorizer__min_df': [1, 2], 'countvectorizer__max_df': [0.25, 0.5]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'logisticregression__C': [0.01, 0.1, 1.0],\n",
    "          'countvectorizer__min_df': [1, 2],\n",
    "          'countvectorizer__max_df': [0.25, 0.5]}\n",
    "grid_search = GridSearchCV(lr, params, n_jobs=-1, return_train_score=True)\n",
    "grid_search.fit(df['tokens'], df['politics'])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.88120135220135221, 0.0022425946809482632)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.set_params(**grid_search.best_params_)\n",
    "score = cross_val_score(lr, df['tokens'], df['politics'], cv=folds, n_jobs=-1)\n",
    "score.mean(), score.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.77080070120070121, 0.014931987277351011)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = make_pipeline(CountVectorizer(analyzer=identity), \n",
    "                    KNeighborsClassifier(metric='cosine'))    \n",
    "knn_score = cross_val_score(knn, df['tokens'], df['politics'], cv=folds, n_jobs=-1)\n",
    "knn_score.mean(), knn_score.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('countvectorizer', CountVectorizer(analyzer=<cyfunction identity at 0x7f4a8a4a0a58>,\n",
       "        binary=False, decode_error='strict', dtype=<class 'numpy.int64'>,\n",
       "        encoding='utf-8', input='content', lowercase=True, max_df=1.0,\n",
       "        max_features=None, min_df=1, ngram_range=(1, 1), prepr...osine',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'))]),\n",
       "       fit_params=None, iid=True, n_jobs=3,\n",
       "       param_grid={'kneighborsclassifier__n_neighbors': [2, 5, 10, 25, 50], 'countvectorizer__min_df': [1, 2], 'countvectorizer__max_df': [0.25, 0.5]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'kneighborsclassifier__n_neighbors': [2, 5, 10, 25, 50],\n",
    "          'countvectorizer__min_df': [1, 2],\n",
    "          'countvectorizer__max_df': [0.25, 0.5]}\n",
    "grid_search = GridSearchCV(knn, params, n_jobs=3, return_train_score=True)\n",
    "grid_search.fit(df['tokens'], df['politics'])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.87439414819414818, 0.010516405030673007)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.set_params(**grid_search.best_params_)\n",
    "knn_score = cross_val_score(knn, df['tokens'], df['politics'], cv=folds, n_jobs=-1)\n",
    "knn_score.mean(), knn_score.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'countvectorizer__max_df': 0.25,\n",
       " 'countvectorizer__min_df': 1,\n",
       " 'kneighborsclassifier__n_neighbors': 25}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = make_pipeline(CountVectorizer(analyzer=identity), \n",
    "                    SelectKBest(mutual_info_classif),\n",
    "                    KNeighborsClassifier(metric='cosine'))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('countvectorizer', CountVectorizer(analyzer=<cyfunction identity at 0x7f4a8a4a0a58>,\n",
       "        binary=False, decode_error='strict', dtype=<class 'numpy.int64'>,\n",
       "        encoding='utf-8', input='content', lowercase=True, max_df=0.25,\n",
       "        max_features=None, min_df=2, ngram_range=(1, 1), prep...osine',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'))]),\n",
       "       fit_params=None, iid=True, n_jobs=4,\n",
       "       param_grid={'kneighborsclassifier__n_neighbors': [5, 10, 20], 'selectkbest__k': [1000, 5000, 10000, 20000, 'all'], 'countvectorizer__min_df': [1, 2], 'countvectorizer__max_df': [0.25, 0.5]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'kneighborsclassifier__n_neighbors': [5, 10],\n",
    "          'selectkbest__k':[1000, 5000, 10000],\n",
    "          'countvectorizer__min_df': [1, 2],\n",
    "          'countvectorizer__max_df': [0.25, 0.5]}\n",
    "grid_search = GridSearchCV(knn, params, n_jobs=4, return_train_score=True)\n",
    "grid_search.fit(df['tokens'], df['politics'])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'countvectorizer__max_df': 0.25,\n",
       " 'countvectorizer__min_df': 1,\n",
       " 'kneighborsclassifier__n_neighbors': 5,\n",
       " 'selectkbest__k': 5000}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.87499995079995085, 0.0045172840087310722)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.set_params(**grid_search.best_params_)\n",
    "knn_score = cross_val_score(knn, df['tokens'], df['politics'], cv=folds, n_jobs=-1)\n",
    "knn_score.mean(), knn_score.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
