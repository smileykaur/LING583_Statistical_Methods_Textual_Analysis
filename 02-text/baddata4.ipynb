{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "Example 4-1. Smart quotes and ISO-8859-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'-\\x93\\x805, please\\x94-'\n"
     ]
    }
   ],
   "source": [
    "b = [45,147, 128, 53, 44, 32, 112, 108, 101, 97, 115, 101, 148,45]\n",
    "s = bytes(c)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-“€5, please”-\n"
     ]
    }
   ],
   "source": [
    "print(s.decode('cp1252'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-5, please-\n"
     ]
    }
   ],
   "source": [
    "print(s.decode('iso-8859-1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "print(len(s.decode('cp1252')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "print(len(s.decode('iso-8859-1')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "Example 4-2. Generating test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_alnum_sample(out, codec, n):\n",
    "    \"\"\"\n",
    "    Look at the first n unicode code points\n",
    "    if that unicode character is alphanumeric\n",
    "    and can be encoded by codec write the encoded\n",
    "    character to out\n",
    "    \"\"\"\n",
    "    for x in range(n):\n",
    "        try:\n",
    "            u = chr(x)\n",
    "            if u.isalnum():\n",
    "                b = u.encode(codec)\n",
    "                out.write(b)\n",
    "        except:\n",
    "            # skip u if codec cannot represent it\n",
    "            pass\n",
    "    out.write(b'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "codecs = ['ascii', 'cp437', 'cp858', 'cp1252', 'iso-8859-1', 'macroman', 'utf-8', 'utf-16']\n",
    "for codec in codecs:\n",
    "    with open('%s_alnum.txt' % codec, mode='wb') as out:\n",
    "        make_alnum_sample(out, codec, 512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Example 4-4. Snippets of non-ASCII text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_non_ascii_snippets(s, n_before=15, n_after=15):\n",
    "    \"\"\"\n",
    "    s is a byte string possibly containing non-ascii\n",
    "    characters\n",
    "    n_before and n_after specify a window size\n",
    "\n",
    "    this function is a generator for snippets\n",
    "    containing the n_before bytes before a non-ascii\n",
    "    character, the non-ascii byte itself, and the\n",
    "    n_after bytes that follow it.\n",
    "    \"\"\"\n",
    "    for idx, c in enumerate(s):\n",
    "        if c > 127:\n",
    "            start = max(idx - n_before, 0)\n",
    "            end = idx + n_after + 1\n",
    "            yield(s[start:end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "CODECS = ['cp858', 'cp1252', 'macroman']\n",
    "def test_codecs(s, codecs=CODECS):\n",
    "    \"\"\"\n",
    "    prints the codecs that can decode s to a Unicode\n",
    "    string and those unicode strings\n",
    "    \"\"\"\n",
    "    max_len = max(map(len, codecs))\n",
    "    for codec in codecs:\n",
    "        try:\n",
    "            u = s.decode(codec)\n",
    "            print(codec.rjust(max_len) + ': ' + u)\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cp858: -ôÇ5, pleaseö-\n",
      "  cp1252: -“€5, please”-\n",
      "macroman: -ìÄ5, pleaseî-\n"
     ]
    }
   ],
   "source": [
    "b = [45,147, 128, 53, 44, 32, 112, 108, 101, 97, 115, 101, 148,45]\n",
    "s = bytes(c)\n",
    "test_codecs(next(stream_non_ascii_snippets(s)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Example 4-5. Frequency-count snippets of non-ASCII text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_non_ascii_byte_counts(s):\n",
    "    \"\"\"\n",
    "    returns {code point: count}\n",
    "    for non-ASCII code points\n",
    "    \"\"\"\n",
    "    counts = defaultdict(int)\n",
    "    for c in s:\n",
    "        if c > 127:\n",
    "            counts[c] += 1\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_targeted_non_ascii_snippets(s, target_byte, n_before=15, n_after=15):\n",
    "    \"\"\"\n",
    "    s is a byte string possibly containing non-ascii\n",
    "    characters\n",
    "    target_byte is code point\n",
    "    n_before and n_after specify a window size\n",
    "\n",
    "    this function is a generator for snippets\n",
    "    containing the n_before bytes before\n",
    "    target_byte, target_byte itself, and the n_after\n",
    "    bytes that follow it.\n",
    "    \"\"\"\n",
    "    for idx, c in enumerate(s):\n",
    "        if c == target_byte:\n",
    "            start = max(idx - n_before, 0)\n",
    "            end = idx + n_after + 1\n",
    "            yield(s[start:end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(148, 1), (147, 1), (128, 1)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(get_non_ascii_byte_counts(s).items(), key=itemgetter(1,0), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cp858: pleaseö-\n",
      "  cp1252: please”-\n",
      "macroman: pleaseî-\n"
     ]
    }
   ],
   "source": [
    "it = stream_targeted_non_ascii_snippets(s, 148, n_before=6)\n",
    "test_codecs(next(it))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Example 4-7. Normalizing text from Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\\xbb\\xb5\\xbc\\xcb\\xe7\\xe5\\xcc\\x80\\x81\\xae\\x82\\xe9\\x83\\xe6\\xe8\\xed\\xea\\xeb\\xec\\x84\\xf1\\xee\\xef\\xcd\\x85\\xaf\\xf4\\xf2\\xf3\\x86\\xa7\\x88\\x87\\x89\\x8b\\x8a\\x8c\\xbe\\x8d\\x8f\\x8e\\x90\\x91\\x93\\x92\\x94\\x95\\x96\\x98\\x97\\x99\\x9b\\x9a\\xbf\\x9d\\x9c\\x9e\\x9f\\xd8\\xf5\\xce\\xcf\\xd9\\xc4\\n'\n"
     ]
    }
   ],
   "source": [
    "with open('macroman_alnum.txt', mode='rb') as f:\n",
    "    print(f.readline())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyzªµºÀÁÂÃÄÅÆÇÈÉÊËÌÍÎÏÑÒÓÔÕÖØÙÚÛÜßàáâãäåæçèéêëìíîïñòóôõöøùúûüÿıŒœŸƒ\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('macroman_alnum.txt', mode='rb') as f:\n",
    "    print(f.readline().decode('macroman'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyzªµºÀÁÂÃÄÅÆÇÈÉÊËÌÍÎÏÑÒÓÔÕÖØÙÚÛÜßàáâãäåæçèéêëìíîïñòóôõöøùúûüÿıŒœŸƒ\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('macroman_alnum.txt', encoding='macroman') as f:\n",
    "    print(f.readline())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "Example 4-8. Decoding URL encoded text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eqn=1%2B2%3D%3D3'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urllib.parse.urlencode({'eqn': '1+2==3'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'www.example.com/test?eqn=1+2==3'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 'www.example.com/test?eqn=1%2B2%3D%3D3'\n",
    "urllib.parse.unquote(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Example 4-9. Decoding HTML encoded text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "&lt;script&gt;//Do Some &#201;v&#238;l&lt;/script&gt;\n"
     ]
    }
   ],
   "source": [
    "s = '<script>//Do Some Évîl</script>'\n",
    "encoded = html.escape(s).encode('ascii', 'xmlcharrefreplace').decode('ascii')\n",
    "print(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<script>//Do Some Évîl</script>\n"
     ]
    }
   ],
   "source": [
    "print(html.unescape(encoded))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Example 4-10. Decoding redundantly HTML encoded text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "&amp;amp;lt;script&amp;amp;gt;//Do Some &amp;amp;#201;v&amp;amp;#238;l&amp;amp;lt;/script&amp;amp;gt;\n"
     ]
    }
   ],
   "source": [
    "# add a few more layers of encoding\n",
    "ss = html.escape(encoded).encode('ascii', 'xmlcharrefreplace').decode('ascii')\n",
    "ss = html.escape(ss).encode('ascii','xmlcharrefreplace').decode('ascii')\n",
    "print(ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "&amp;lt;script&amp;gt;//Do Some &amp;#201;v&amp;#238;l&amp;lt;/script&amp;gt;\n",
      "&lt;script&gt;//Do Some &#201;v&#238;l&lt;/script&gt;\n",
      "<script>//Do Some Évîl</script>\n"
     ]
    }
   ],
   "source": [
    "# now decode until length becomes constant\n",
    "while len(ss) != len(html.unescape(ss)):\n",
    "    ss = html.unescape(ss)\n",
    "    print(ss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Example 4-11. Quoted CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import csv\n",
    "# s behaves like a file opened for reading\n",
    ">>> s = StringIO.StringIO('''Name,Job Description\n",
    "\"Bolton, Michael \"\"Mike\"\"\",\"Programmer\"\n",
    "Bolton,Michael \"Mike\",Programmer''')\n",
    ">>> # When we count the fields per line,\n",
    ">>> # str.split is confused by Name\n",
    ">>> map(len, [line.split(',') for line in s])\n",
    "[2, 3, 3]\n",
    ">>> # csv.reader understands quoted name\n",
    ">>> s.seek(0)\n",
    ">>> map(len, csv.reader(s))\n",
    "[2, 2, 3\n",
    ">>> s.seek(0)\n",
    ">>> data = [row for row in csv.reader(s)]\n",
    ">>> # with quotes the comma in the name\n",
    ">>> # is not a delimiter\n",
    ">>> data[1][0]\n",
    "'Bolton, Michael \"Mike\"'\n",
    ">>> # without quotes all commas are delimiters\n",
    ">>> data[2][0]\n",
    "'Bolton'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = io.StringIO('''Name,Job Description\n",
    "\"Bolton, Michael \"\"Mike\"\"\",\"Programmer\"\n",
    "Bolton,Michael \"Mike\",Programmer''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 3]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# When we count the fields per line,\n",
    "# str.split is confused by Name\n",
    "list(map(len, [line.split(',') for line in s]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 2, 3]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# csv.reader understands quoted name\n",
    "s.seek(0)\n",
    "list(map(len, csv.reader(s)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.seek(0)\n",
    "data = [row for row in csv.reader(s)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bolton, Michael \"Mike\"'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with quotes the comma in the name\n",
    "# is not a delimiter\n",
    "data[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bolton'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# without quotes all commas are delimiters\n",
    "data[2][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
